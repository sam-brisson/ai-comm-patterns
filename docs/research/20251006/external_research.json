{
  "timestamp": "2025-10-06T09:25:56.038252",
  "depth": "light",
  "sources": {
    "arxiv": [
      {
        "title": "Reward Models are Metrics in a Trench Coat",
        "authors": [
          "Sebastian Gehrmann"
        ],
        "summary": "The emergence of reinforcement learning in post-training of large language models has sparked significant interest in reward models. Reward models assess the quality of sampled model outputs to generate training signals. This task is also performed by evaluation metrics that monitor the performance of an AI model. We find that the two research areas are mostly separate, leading to redundant terminology and repeated pitfalls. Common challenges include susceptibility to spurious correlations, impact on downstream reward hacking, methods to improve data quality, and approaches to meta-evaluation. Our position paper argues that a closer collaboration between the fields can help overcome these issues. To that end, we show how metrics outperform reward models on specific tasks and provide an extensive survey of the two areas. Grounded in this survey, we point to multiple research topics in which closer alignment can improve reward models and metrics in areas such as preference elicitation methods, avoidance of spurious correlations and reward hacking, and calibration-aware meta-evaluation.",
        "url": "http://arxiv.org/abs/2510.03231v1",
        "published": "2025-10-03T17:59:44Z",
        "categories": [
          "cs.CL",
          "cs.AI"
        ],
        "source": "arxiv"
      },
      {
        "title": "Abstain and Validate: A Dual-LLM Policy for Reducing Noise in Agentic\n  Program Repair",
        "authors": [
          "Jos\u00e9 Cambronero",
          "Michele Tufano",
          "Sherry Shi",
          "Renyao Wei",
          "Grant Uy",
          "Runxiang Cheng",
          "Chin-Jung Liu",
          "Shiying Pan",
          "Satish Chandra",
          "Pat Rondon"
        ],
        "summary": "Agentic Automated Program Repair (APR) is increasingly tackling complex, repository-level bugs in industry, but ultimately agent-generated patches still need to be reviewed by a human before committing them to ensure they address the bug. Showing unlikely patches to developers can lead to substantial noise, wasting valuable developer time and eroding trust in automated code changes. We introduce two complementary LLM-based policies to reduce such noise: bug abstention and patch validation policies. Bug abstention excludes bugs that the agentic APR system is unlikely to fix. Patch validation rejects patches that are unlikely to be a good fix for the given bug. We evaluate both policies on three sets of bugs from Google's codebase, and their candidate patches generated by an internal agentic APR system. On a set of 174 human-reported bugs, removing bugs and patch trajectories rejected by our policies can raise success rates by up to 13 percentage points and 15 percentage points, respectively, and by up to 39 percentage points in combination. On null pointer exceptions and sanitizer-reported bugs with machine-generated bug reports, patch validation also improves average single-sample success rates. This two-policy approach provides a practical path to the reliable, industrial-scale deployment of agentic APR systems.",
        "url": "http://arxiv.org/abs/2510.03217v1",
        "published": "2025-10-03T17:53:28Z",
        "categories": [
          "cs.SE",
          "cs.AI"
        ],
        "source": "arxiv"
      },
      {
        "title": "Wave-GMS: Lightweight Multi-Scale Generative Model for Medical Image\n  Segmentation",
        "authors": [
          "Talha Ahmed",
          "Nehal Ahmed Shaikh",
          "Hassan Mohy-ud-Din"
        ],
        "summary": "For equitable deployment of AI tools in hospitals and healthcare facilities, we need Deep Segmentation Networks that offer high performance and can be trained on cost-effective GPUs with limited memory and large batch sizes. In this work, we propose Wave-GMS, a lightweight and efficient multi-scale generative model for medical image segmentation. Wave-GMS has a substantially smaller number of trainable parameters, does not require loading memory-intensive pretrained vision foundation models, and supports training with large batch sizes on GPUs with limited memory. We conducted extensive experiments on four publicly available datasets (BUS, BUSI, Kvasir-Instrument, and HAM10000), demonstrating that Wave-GMS achieves state-of-the-art segmentation performance with superior cross-domain generalizability, while requiring only ~2.6M trainable parameters. Code is available at https://github.com/ATPLab-LUMS/Wave-GMS.",
        "url": "http://arxiv.org/abs/2510.03216v1",
        "published": "2025-10-03T17:53:16Z",
        "categories": [
          "eess.IV",
          "cs.AI",
          "cs.CV"
        ],
        "source": "arxiv"
      },
      {
        "title": "Automatic Generation of Digital Twins for Network Testing",
        "authors": [
          "Shenjia Ding",
          "David Flynn",
          "Paul Harvey"
        ],
        "summary": "The increased use of software in the operation and management of telecommunication networks has moved the industry one step closer to realizing autonomous network operation. One consequence of this shift is the significantly increased need for testing and validation before such software can be deployed. Complementing existing simulation or hardware-based approaches, digital twins present an environment to achieve this testing; however, they require significant time and human effort to configure and execute. This paper explores the automatic generation of digital twins to provide efficient and accurate validation tools, aligned to the ITU-T autonomous network architecture's experimentation subsystem. We present experimental results for an initial use case, demonstrating that the approach is feasible in automatically creating efficient digital twins with sufficient accuracy to be included as part of existing validation pipelines.",
        "url": "http://arxiv.org/abs/2510.03205v1",
        "published": "2025-10-03T17:43:11Z",
        "categories": [
          "cs.NI",
          "cs.LG"
        ],
        "source": "arxiv"
      },
      {
        "title": "MonSTeR: a Unified Model for Motion, Scene, Text Retrieval",
        "authors": [
          "Luca Collorone",
          "Matteo Gioia",
          "Massimiliano Pappa",
          "Paolo Leoni",
          "Giovanni Ficarra",
          "Or Litany",
          "Indro Spinelli",
          "Fabio Galasso"
        ],
        "summary": "Intention drives human movement in complex environments, but such movement can only happen if the surrounding context supports it. Despite the intuitive nature of this mechanism, existing research has not yet provided tools to evaluate the alignment between skeletal movement (motion), intention (text), and the surrounding context (scene). In this work, we introduce MonSTeR, the first MOtioN-Scene-TExt Retrieval model. Inspired by the modeling of higher-order relations, MonSTeR constructs a unified latent space by leveraging unimodal and cross-modal representations. This allows MonSTeR to capture the intricate dependencies between modalities, enabling flexible but robust retrieval across various tasks. Our results show that MonSTeR outperforms trimodal models that rely solely on unimodal representations. Furthermore, we validate the alignment of our retrieval scores with human preferences through a dedicated user study. We demonstrate the versatility of MonSTeR's latent space on zero-shot in-Scene Object Placement and Motion Captioning. Code and pre-trained models are available at github.com/colloroneluca/MonSTeR.",
        "url": "http://arxiv.org/abs/2510.03200v1",
        "published": "2025-10-03T17:37:50Z",
        "categories": [
          "cs.CV"
        ],
        "source": "arxiv"
      },
      {
        "title": "LEAML: Label-Efficient Adaptation to Out-of-Distribution Visual Tasks\n  for Multimodal Large Language Models",
        "authors": [
          "Ci-Siang Lin",
          "Min-Hung Chen",
          "Yu-Yang Sheng",
          "Yu-Chiang Frank Wang"
        ],
        "summary": "Multimodal Large Language Models (MLLMs) have achieved strong performance on general visual benchmarks but struggle with out-of-distribution (OOD) tasks in specialized domains such as medical imaging, where labeled data is limited and expensive. We introduce LEAML, a label-efficient adaptation framework that leverages both scarce labeled VQA samples and abundant unlabeled images. Our approach generates domain-relevant pseudo question-answer pairs for unlabeled data using a QA generator regularized by caption distillation. Importantly, we selectively update only those neurons most relevant to question-answering, enabling the QA Generator to efficiently acquire domain-specific knowledge during distillation. Experiments on gastrointestinal endoscopy and sports VQA demonstrate that LEAML consistently outperforms standard fine-tuning under minimal supervision, highlighting the effectiveness of our proposed LEAML framework.",
        "url": "http://arxiv.org/abs/2510.03232v1",
        "published": "2025-10-03T17:59:56Z",
        "categories": [
          "cs.CV"
        ],
        "source": "arxiv"
      },
      {
        "title": "Reward Models are Metrics in a Trench Coat",
        "authors": [
          "Sebastian Gehrmann"
        ],
        "summary": "The emergence of reinforcement learning in post-training of large language models has sparked significant interest in reward models. Reward models assess the quality of sampled model outputs to generate training signals. This task is also performed by evaluation metrics that monitor the performance of an AI model. We find that the two research areas are mostly separate, leading to redundant terminology and repeated pitfalls. Common challenges include susceptibility to spurious correlations, impact on downstream reward hacking, methods to improve data quality, and approaches to meta-evaluation. Our position paper argues that a closer collaboration between the fields can help overcome these issues. To that end, we show how metrics outperform reward models on specific tasks and provide an extensive survey of the two areas. Grounded in this survey, we point to multiple research topics in which closer alignment can improve reward models and metrics in areas such as preference elicitation methods, avoidance of spurious correlations and reward hacking, and calibration-aware meta-evaluation.",
        "url": "http://arxiv.org/abs/2510.03231v1",
        "published": "2025-10-03T17:59:44Z",
        "categories": [
          "cs.CL",
          "cs.AI"
        ],
        "source": "arxiv"
      },
      {
        "title": "Improving GUI Grounding with Explicit Position-to-Coordinate Mapping",
        "authors": [
          "Suyuchen Wang",
          "Tianyu Zhang",
          "Ahmed Masry",
          "Christopher Pal",
          "Spandana Gella",
          "Bang Liu",
          "Perouz Taslakian"
        ],
        "summary": "GUI grounding, the task of mapping natural-language instructions to pixel coordinates, is crucial for autonomous agents, yet remains difficult for current VLMs. The core bottleneck is reliable patch-to-pixel mapping, which breaks when extrapolating to high-resolution displays unseen during training. Current approaches generate coordinates as text tokens directly from visual features, forcing the model to infer complex position-to-pixel mappings implicitly; as a result, accuracy degrades and failures proliferate on new resolutions. We address this with two complementary innovations. First, RULER tokens serve as explicit coordinate markers, letting the model reference positions similar to gridlines on a map and adjust rather than generate coordinates from scratch. Second, Interleaved MRoPE (I-MRoPE) improves spatial encoding by ensuring that width and height dimensions are represented equally, addressing the asymmetry of standard positional schemes. Experiments on ScreenSpot, ScreenSpot-V2, and ScreenSpot-Pro show consistent gains in grounding accuracy, with the largest improvements on high-resolution interfaces. By providing explicit spatial guidance rather than relying on implicit learning, our approach enables more reliable GUI automation across diverse resolutions and platforms.",
        "url": "http://arxiv.org/abs/2510.03230v1",
        "published": "2025-10-03T17:59:34Z",
        "categories": [
          "cs.CV",
          "cs.AI"
        ],
        "source": "arxiv"
      },
      {
        "title": "MIXER: Mixed Hyperspherical Random Embedding Neural Network for Texture\n  Recognition",
        "authors": [
          "Ricardo T. Fares",
          "Lucas C. Ribas"
        ],
        "summary": "Randomized neural networks for representation learning have consistently achieved prominent results in texture recognition tasks, effectively combining the advantages of both traditional techniques and learning-based approaches. However, existing approaches have so far focused mainly on improving cross-information prediction, without introducing significant advancements to the overall randomized network architecture. In this paper, we propose Mixer, a novel randomized neural network for texture representation learning. At its core, the method leverages hyperspherical random embeddings coupled with a dual-branch learning module to capture both intra- and inter-channel relationships, further enhanced by a newly formulated optimization problem for building rich texture representations. Experimental results have shown the interesting results of the proposed approach across several pure texture benchmarks, each with distinct characteristics and challenges. The source code will be available upon publication.",
        "url": "http://arxiv.org/abs/2510.03228v1",
        "published": "2025-10-03T17:58:04Z",
        "categories": [
          "cs.CV"
        ],
        "source": "arxiv"
      },
      {
        "title": "Absence of quantum Darwinism as a resource in secure quantum\n  communication and computation",
        "authors": [
          "Bishal Kumar Das",
          "Sourav Manna",
          "Vaibhav Madhok"
        ],
        "summary": "The emergence of classical world from underlying quantum mechanics is characterized by not only vanishing quantum correlations but also an unfolding of objectivity also known as quantum Darwinism. We show that the absence of this objectivity has a quantum advantage in cryptography and also provides the crucial missing link in efficient classical simulation of quantum circuits with zero discord. For this purpose, we consider a model of mixed state quantum computation where one is promised concordant states at all stages of the quantum circuit. A concordant quantum state has zero discord with respect to any part and there exists a basis made up of a tensor product of orthonormal local subsystem basis in which the density matrix is diagonal. Efficient classical simulation of concordant computation has surprisingly been an outstanding question in quantum information theory. We argue that a key ingredient of an efficient classical simulation algorithm, a knowledge of the local basis in which the multi-party state is diagonal, is made available by quantum Darwinism. Concordant states in the absence of quantum Darwinism cannot be efficiently simulated by existing methods and give a cryptographic advantage in communication. We show this by giving a protocol for secure quantum communication that exploits this insight. Our work also has implications for the quantum-classical border and we discuss how objectivity emerging out of Darwinism demarcates this border in three ways - empirical based on our observations and experience of objectivity, information theoretic due to the absence of any quantum correlations and lastly computational in the sense discussed above. Lastly, we show that the quantum-classical boundary as drawn by quantum Darwinism as well by what can be simulated efficiently in a mixed state quantum computation aligns with the boundary given by Hardy",
        "url": "http://arxiv.org/abs/2510.03225v1",
        "published": "2025-10-03T17:57:26Z",
        "categories": [
          "quant-ph"
        ],
        "source": "arxiv"
      },
      {
        "title": "LEAML: Label-Efficient Adaptation to Out-of-Distribution Visual Tasks\n  for Multimodal Large Language Models",
        "authors": [
          "Ci-Siang Lin",
          "Min-Hung Chen",
          "Yu-Yang Sheng",
          "Yu-Chiang Frank Wang"
        ],
        "summary": "Multimodal Large Language Models (MLLMs) have achieved strong performance on general visual benchmarks but struggle with out-of-distribution (OOD) tasks in specialized domains such as medical imaging, where labeled data is limited and expensive. We introduce LEAML, a label-efficient adaptation framework that leverages both scarce labeled VQA samples and abundant unlabeled images. Our approach generates domain-relevant pseudo question-answer pairs for unlabeled data using a QA generator regularized by caption distillation. Importantly, we selectively update only those neurons most relevant to question-answering, enabling the QA Generator to efficiently acquire domain-specific knowledge during distillation. Experiments on gastrointestinal endoscopy and sports VQA demonstrate that LEAML consistently outperforms standard fine-tuning under minimal supervision, highlighting the effectiveness of our proposed LEAML framework.",
        "url": "http://arxiv.org/abs/2510.03232v1",
        "published": "2025-10-03T17:59:56Z",
        "categories": [
          "cs.CV"
        ],
        "source": "arxiv"
      },
      {
        "title": "Reward Models are Metrics in a Trench Coat",
        "authors": [
          "Sebastian Gehrmann"
        ],
        "summary": "The emergence of reinforcement learning in post-training of large language models has sparked significant interest in reward models. Reward models assess the quality of sampled model outputs to generate training signals. This task is also performed by evaluation metrics that monitor the performance of an AI model. We find that the two research areas are mostly separate, leading to redundant terminology and repeated pitfalls. Common challenges include susceptibility to spurious correlations, impact on downstream reward hacking, methods to improve data quality, and approaches to meta-evaluation. Our position paper argues that a closer collaboration between the fields can help overcome these issues. To that end, we show how metrics outperform reward models on specific tasks and provide an extensive survey of the two areas. Grounded in this survey, we point to multiple research topics in which closer alignment can improve reward models and metrics in areas such as preference elicitation methods, avoidance of spurious correlations and reward hacking, and calibration-aware meta-evaluation.",
        "url": "http://arxiv.org/abs/2510.03231v1",
        "published": "2025-10-03T17:59:44Z",
        "categories": [
          "cs.CL",
          "cs.AI"
        ],
        "source": "arxiv"
      },
      {
        "title": "Improving GUI Grounding with Explicit Position-to-Coordinate Mapping",
        "authors": [
          "Suyuchen Wang",
          "Tianyu Zhang",
          "Ahmed Masry",
          "Christopher Pal",
          "Spandana Gella",
          "Bang Liu",
          "Perouz Taslakian"
        ],
        "summary": "GUI grounding, the task of mapping natural-language instructions to pixel coordinates, is crucial for autonomous agents, yet remains difficult for current VLMs. The core bottleneck is reliable patch-to-pixel mapping, which breaks when extrapolating to high-resolution displays unseen during training. Current approaches generate coordinates as text tokens directly from visual features, forcing the model to infer complex position-to-pixel mappings implicitly; as a result, accuracy degrades and failures proliferate on new resolutions. We address this with two complementary innovations. First, RULER tokens serve as explicit coordinate markers, letting the model reference positions similar to gridlines on a map and adjust rather than generate coordinates from scratch. Second, Interleaved MRoPE (I-MRoPE) improves spatial encoding by ensuring that width and height dimensions are represented equally, addressing the asymmetry of standard positional schemes. Experiments on ScreenSpot, ScreenSpot-V2, and ScreenSpot-Pro show consistent gains in grounding accuracy, with the largest improvements on high-resolution interfaces. By providing explicit spatial guidance rather than relying on implicit learning, our approach enables more reliable GUI automation across diverse resolutions and platforms.",
        "url": "http://arxiv.org/abs/2510.03230v1",
        "published": "2025-10-03T17:59:34Z",
        "categories": [
          "cs.CV",
          "cs.AI"
        ],
        "source": "arxiv"
      },
      {
        "title": "MIXER: Mixed Hyperspherical Random Embedding Neural Network for Texture\n  Recognition",
        "authors": [
          "Ricardo T. Fares",
          "Lucas C. Ribas"
        ],
        "summary": "Randomized neural networks for representation learning have consistently achieved prominent results in texture recognition tasks, effectively combining the advantages of both traditional techniques and learning-based approaches. However, existing approaches have so far focused mainly on improving cross-information prediction, without introducing significant advancements to the overall randomized network architecture. In this paper, we propose Mixer, a novel randomized neural network for texture representation learning. At its core, the method leverages hyperspherical random embeddings coupled with a dual-branch learning module to capture both intra- and inter-channel relationships, further enhanced by a newly formulated optimization problem for building rich texture representations. Experimental results have shown the interesting results of the proposed approach across several pure texture benchmarks, each with distinct characteristics and challenges. The source code will be available upon publication.",
        "url": "http://arxiv.org/abs/2510.03228v1",
        "published": "2025-10-03T17:58:04Z",
        "categories": [
          "cs.CV"
        ],
        "source": "arxiv"
      },
      {
        "title": "Plugging Leaks in Fault-Tolerant Quantum Computation and Verification",
        "authors": [
          "Theodoros Kapourniotis",
          "Dominik Leichtle",
          "Luka Music",
          "Harold Ollivier"
        ],
        "summary": "With the advent of quantum cloud computing, the security of delegated quantum computation has become of utmost importance. While multiple statistically secure blind verification schemes in the prepare-and-send model have been proposed, none of them achieves full quantum fault-tolerance, a prerequisite for useful verification on scalable quantum computers. In this paper, we present the first fault-tolerant blind verification scheme for universal quantum computations able to handle secret-dependent noise on the verifier's quantum device. Composable security of the proposed protocol is proven in the Abstract Cryptography framework.   Our main tools are two novel distillation protocols that turn secret-dependent noise into secret-independent noise. The first one is run by the verifier and acts on its noisy gates, while the second and more complex one is run entirely on the prover's device and acts on states provided by the verifier. Both are required to overcome the leakage induced by secret-dependent noise. We use these protocols to prepare states in the X-Y-plane whose noise is overwhelmingly secret-independent, which then allows us to verify with exponential confidence arbitrary fault-tolerant BQP computations.",
        "url": "http://arxiv.org/abs/2510.03227v1",
        "published": "2025-10-03T17:57:59Z",
        "categories": [
          "quant-ph"
        ],
        "source": "arxiv"
      }
    ],
    "discussions": [
      {
        "title": "Human-AI Collaborative Coding Patterns",
        "summary": "Discussion about effective patterns for human-AI pair programming",
        "source": "community_discussion",
        "relevance": "high",
        "date": "2025-10-06T09:25:59.977629",
        "url": "placeholder",
        "engagement": "active"
      },
      {
        "title": "Visual Design Collaboration with AI Tools",
        "summary": "Emerging patterns in visual design workflows with AI assistance",
        "source": "community_discussion",
        "relevance": "high",
        "date": "2025-10-06T09:25:59.977647",
        "url": "placeholder",
        "engagement": "emerging"
      }
    ]
  },
  "trends": {
    "trending_terms": {
      "communication": 4,
      "cognition": 4,
      "collaboration": 3,
      "interface": 2,
      "trust": 1,
      "experience": 1
    },
    "total_papers": 15,
    "recent_focus_areas": [
      "communication",
      "cognition",
      "collaboration",
      "interface",
      "trust"
    ],
    "analysis_note": "Based on keyword frequency in recent research papers"
  },
  "opportunities": [
    {
      "topic": "communication",
      "research_frequency": 4,
      "gap_level": "high",
      "research_basis": "Appears 4 times in recent research",
      "suggested_focus": "Study communication patterns that enhance human-AI collaboration"
    },
    {
      "topic": "cognition",
      "research_frequency": 4,
      "gap_level": "high",
      "research_basis": "Appears 4 times in recent research",
      "suggested_focus": "Investigate cognition in the context of human-AI collaboration"
    },
    {
      "topic": "collaboration",
      "research_frequency": 3,
      "gap_level": "high",
      "research_basis": "Appears 3 times in recent research",
      "suggested_focus": "Explore new patterns of human-AI collaborative workflows"
    }
  ]
}